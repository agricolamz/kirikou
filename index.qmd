---
title: "Kirikou NLP"
date: today
date-format: D.MM.YYYY
format: 
  html:
    toc: true
df-print: paged
execute:
  warning: false
  message: false
fig-height: 6
fig-width: 10
editor: source
code-fold: true
editor_options: 
  chunk_output_type: console
---

Я решил разбить все на три группы по переменным `socio_family_adoptive` и `residence_place`. Вот самые частотные униграммы:

```{r}
#| message: false

# setwd("/home/agricolamz/work/articles/2025_kirikou/repo/")
library(tidyverse)
theme_set(theme_minimal()+theme(legend.position = "bottom", 
                                text = element_text(size = 16)))
library(tidytext)

readxl::read_xlsx("kirikou_annotations.xlsx", sheet = "kirikou Mano") |>
  select(-elicitation_date) |> 
  mutate(text_type = "kirikou") |>
  bind_rows(readxl::read_xlsx("kirikou_annotations.xlsx", sheet = "folktales Mano children") |> 
              mutate(text_type = "folktales")) |> 
  rename(chunk_structure = `chunk structure`) |> 
  mutate(txenfant = str_remove_all(txenfant , "[/+]"),
         txenfant = str_remove_all(txenfant, "\\[.*?\\]"),
         txenfant = if_else(is.na(txenfant), "", txenfant),
         ft = if_else(is.na(ft), "", ft),
         chunk_structure = if_else(is.na(chunk_structure), "", chunk_structure)) |>
  add_count(name, age) |> 
  rename(n_chunks = n) |> 
  group_by(name, age, socio_family_adoptive, text_type, residence_place, n_chunks) |> 
  summarize(text = str_c(txenfant, collapse = " "),
            chunk_structure = str_c(chunk_structure, collapse = " "),
            ft = str_c(ft, collapse = " ")) |> 
  mutate(age_group = "children") |> 
  ungroup() ->
  mano_chi_corpus

readxl::read_xlsx("kirikou_annotations.xlsx", sheet = "folktales Mano adults") |> 
  mutate(age = 100,
         text_type = "folktales") |> 
  rename(txenfant = `txenfant = tx`,
         chunk_structure = `chunk structure`) |> 
  mutate(txenfant = str_remove_all(txenfant , "[/+]"),
         txenfant = str_remove_all(txenfant, "\\[.*?\\]"),
         txenfant = if_else(is.na(txenfant), "", txenfant),
         ft = if_else(is.na(ft), "", ft),
         chunk_structure = if_else(is.na(chunk_structure), "", chunk_structure)) |>
  add_count(name, age) |> 
  rename(n_chunks = n) |> 
  group_by(name, age, socio_family_adoptive, text_type, residence_place, n_chunks) |> 
  summarize(text = str_c(txenfant, collapse = " "),
            chunk_structure = str_c(chunk_structure, collapse = " "),
            ft = str_c(ft, collapse = " ")) |> 
  mutate(age_group = "adults") |> 
  bind_rows(mano_chi_corpus) |> 
  mutate(group_var = case_when(text_type == "kirikou" & residence_place == "Nzerekore" & socio_family_adoptive == "Mano" ~ "Kirikou (Nzerekore): Mano",
                               text_type == "kirikou" & residence_place == "Nzerekore" & socio_family_adoptive == "Bilingual" ~ "Kirikou (Nzerekore): Bilingual",
                               text_type == "kirikou" & residence_place != "Nzerekore" ~ "Kirikou (other)",
                               text_type == "folktales" & age_group == "children" ~ "folktales (children)",
                               text_type == "folktales" & age_group == "adults" ~ "folktales (adults)")) |> 
  ungroup() -> 
  mano_corpus

rm(mano_chi_corpus)
```

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = word) |> 
  count(group_var, word) |> 
  group_by(group_var) |> 
  slice_max(n, n = 20) |> 
  mutate(word = reorder_within(word, by = n, within = group_var)) |>  
  ggplot(aes(n, word))+
  geom_col()+
  facet_wrap(~group_var, scales = "free")+
  scale_y_reordered()+
  labs(x = NULL, y = NULL)
```

Из странного я вижу два разных gbaa, которые видимо, по разному набраны. Посмотрим на все символы, которые используются в тексте:

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = characters, token = "characters") |> 
  distinct(characters) |> 
  pull(characters) |> 
  sort()
```

Видимо, проблема с символами, которые записаны по-французски и в МФА, а также с некоторыми символами: исправим.

```{r}
mano_corpus |> 
  mutate(text = str_replace_all(text, "á", "á"),
         text = str_replace_all(text, "á", "á"),
         text = str_replace_all(text, "à", "à"),
         text = str_replace_all(text, "à", "à"),
         text = str_replace_all(text, "á̰", "á̰"),
         text = str_replace_all(text, "á̰", "á̰"),
         text = str_replace_all(text, "à̰", "à̰"),
         text = str_replace_all(text, "à̰", "à̰"),         
         text = str_replace_all(text, "ā", "ā"),
         text = str_replace_all(text, "ā", "ā"),
         text = str_replace_all(text, "ā̰", "ā̰"),
         text = str_replace_all(text, "ā̰", "á̰"),
         text = str_replace_all(text, "a̰", "a̰"),
         text = str_replace_all(text, "é", "é"),
         text = str_replace_all(text, "é", "é"),
         text = str_replace_all(text, "è", "è"),
         text = str_replace_all(text, "è", "è"),
         text = str_replace_all(text, "è", "è"),         
         text = str_replace_all(text, "ē", "ē"),
         text = str_replace_all(text, "ē", "ē"),   
         text = str_replace_all(text, "ɛ̄", "ɛ̄"), 
         text = str_replace_all(text, "ɛ̰̀", "ɛ̰̀"),
         text = str_replace_all(text, "ɛ̰̀", "ɛ̰̀"),
         text = str_replace_all(text, "ɛ̰́", "ɛ̰́"),
         text = str_replace_all(text, "ɛ̰́", "ɛ̰́"),
         text = str_replace_all(text, "ɛ̰̄", "ɛ̰̄"),  
         text = str_replace_all(text, "ɛ̰̄", "ɛ̰̄"),         
         text = str_replace_all(text, "ɛ̰̄", "ɛ̰̄"),         
         text = str_replace_all(text, "í", "í"),
         text = str_replace_all(text, "í", "í"),
         text = str_replace_all(text, "ì", "ì"),
         text = str_replace_all(text, "ì", "ì"),
         text = str_replace_all(text, "ī", "ī"),
         text = str_replace_all(text, "ī", "ī"),
         text = str_replace_all(text, "ī", "ī"),
         text = str_replace_all(text, "ḭ̄", "ḭ̄"),
         text = str_replace_all(text, "ḭ̄", "ḭ̄"),
         text = str_replace_all(text, "ḭ̄", "ḭ̄"),
         text = str_replace_all(text, "ḭ̄", "ḭ̄"),
         text = str_replace_all(text, "ḭ́", "ḭ́"),
         text = str_replace_all(text, "ḭ̀", "ḭ̀"),
         text = str_replace_all(text, "ḭ̀", "ḭ̀"),
         text = str_replace_all(text, "ɩ̀", "ì"),
         text = str_replace_all(text, "ó", "ó"),
         text = str_replace_all(text, "ó", "ó"),
         text = str_replace_all(text, "ò", "ò"),
         text = str_replace_all(text, "ò", "ò"),
         text = str_replace_all(text, "ō", "ō"),
         text = str_replace_all(text, "ō", "ō"),
         text = str_replace_all(text, "ɔ̰́", "ɔ̰́"),
         text = str_replace_all(text, "ɔ̰́", "ɔ̰́"),
         text = str_replace_all(text, "ɔ̰̀", "ɔ̰̀"),
         text = str_replace_all(text, "ɔ̰̀", "ɔ̰̀"),
         text = str_replace_all(text, "ɔ̰̄", "ɔ̰̄"),
         text = str_replace_all(text, "ɔ̰̄", "ɔ̰̄"),
         text = str_replace_all(text, "ú", "ú"),
         text = str_replace_all(text, "ú", "ú"),
         text = str_replace_all(text, "ù", "ù"),
         text = str_replace_all(text, "ù", "ù"),
         text = str_replace_all(text, "ū", "ū"),
         text = str_replace_all(text, "ū", "ū"),
         text = str_replace_all(text, "ṵ́", "ṵ́"),
         text = str_replace_all(text, "ṵ́", "ṵ́"),
         text = str_replace_all(text, "ṵ̄", "ṵ̄"),
         text = str_replace_all(text, "ṵ̄", "ṵ̄"),
         text = str_remove_all(text, "[123¹]")) ->
  mano_corpus
```

Вот что получается после преобразования:

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = characters, token = "characters") |> 
  distinct(characters) |> 
  pull(characters) |> 
  sort()
```

### Частотность

Теперь мы можем снова нарисовать наш график:

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = word) |> 
  count(group_var, word) |> 
  group_by(group_var) |> 
  slice_max(n, n = 20) |> 
  mutate(word = reorder_within(word, by = n, within = group_var)) |> 
  ggplot(aes(n, word))+
  geom_col()+
  facet_wrap(~group_var, scales = "free")+
  scale_y_reordered()+
  labs(x = NULL, y = NULL)
```

Посмотрим на биграммы

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = ngram, token = "ngrams", n = 2) |> 
  count(group_var, ngram) |> 
  group_by(group_var) |> 
  slice_max(n, n = 20) |> 
  mutate(ngram = reorder_within(ngram, by = n, within = group_var)) |> 
  ggplot(aes(n, ngram))+
  geom_col()+
  facet_wrap(~group_var, scales = "free")+
  scale_y_reordered()+
  labs(x = NULL, y = NULL)
```

Посмотрим на трииграммы

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = ngram, token = "ngrams", n = 3) |> 
  count(group_var, ngram) |> 
  group_by(group_var) |> 
  slice_max(n, n = 20) |> 
  mutate(ngram = reorder_within(ngram, by = n, within = group_var)) |> 
  ggplot(aes(n, ngram))+
  geom_col()+
  facet_wrap(~group_var, scales = "free")+
  scale_y_reordered()+
  labs(x = NULL, y = NULL)
```

### tf-idf

Посчитаем меру tf-idf для униграм, биграм и триграм

```{r}
mano_corpus |> 
  unnest_tokens(input = "text", output = "word", token = "words") |>
  count(group_var, word, sort = TRUE) |> 
  bind_tf_idf(word, group_var, n) |> 
  arrange(desc(tf_idf)) |> 
  group_by(group_var) |> 
  slice_max(order_by = tf_idf, n = 10) |> 
  mutate(word = reorder_within(word, n, group_var)) |> 
  ggplot(aes(word, n)) +
  geom_bar(stat="identity") +
  facet_wrap(~ group_var, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL, y = NULL)

mano_corpus |> 
  unnest_tokens(input = "text", output = "ngram", token = "ngrams", n = 2) |>
  count(group_var, ngram, sort = TRUE) |> 
  bind_tf_idf(ngram, group_var, n) |> 
  arrange(desc(tf_idf)) |> 
  group_by(group_var) |> 
  slice_max(order_by = tf_idf, n = 10) |> 
  mutate(ngram = reorder_within(ngram, n, group_var)) |> 
  ggplot(aes(ngram, n)) +
  geom_bar(stat="identity") +
  facet_wrap(~ group_var, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL, y = NULL)

mano_corpus |> 
  unnest_tokens(input = "text", output = "ngram", token = "ngrams", n = 3) |>
  count(group_var, ngram, sort = TRUE) |> 
  bind_tf_idf(ngram, group_var, n) |> 
  arrange(desc(tf_idf)) |> 
  group_by(group_var) |> 
  slice_max(order_by = tf_idf, n = 10) |> 
  mutate(ngram = reorder_within(ngram, n, group_var)) |> 
  ggplot(aes(ngram, n)) +
  geom_bar(stat="identity") +
  facet_wrap(~ group_var, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL, y = NULL)
```

### Lexical diversity

> Но я подумала что было бы интересно не самое частотное посчитать, а наоборот Предположительно оно должно различаться между группами

> The American psychologist and speech pathologist Wendell Johnson (1939, 1944) proposed the type-token ratio (TTR)  (Javris 2019)

Доля уникальных слов из всех слов. Размер --- количество слов в тексте. 

```{r}
mano_corpus |> 
  filter(age != 100) |> 
  unnest_tokens(input = "text", output = "word", token = "words") |> 
  count(name, age, group_var, word) |> 
  group_by(name, age, group_var) |> 
  summarise(size = sum(n),
            richness = n(),
            TTR = richness/size) |> 
  ggplot(aes(age, TTR, color = group_var, label = name))+
  geom_point(aes(size = size))+
  ggrepel::geom_text_repel()+
  labs(size = NULL, color = NULL)
```

Энтропия текстов (чуть больше верю этой мере разнообразия).

```{r}
mano_corpus |> 
  filter(age != 100) |> 
  unnest_tokens(input = "text", output = "word", token = "words") |> 
  count(name, age, group_var, word) |> 
  group_by(name, age, group_var) |> 
  summarise(size = sum(n),
            richness = n(),
            TTR = richness/size,
            entropy = -sum(TTR*log2(TTR))) |> 
  ggplot(aes(age, entropy, color = group_var, label = name))+
  geom_point(aes(size = size))+
  ggrepel::geom_text_repel()+
  labs(size = NULL, color = NULL)
```

Оказывается (Baayen 2008, 222–36) исследовал меры разнообразия и написал несколько интересных мыслей.

```{r}
mano_corpus |> 
  unnest_tokens(input = "text", output = "word", token = "words") |> 
  group_by(name, age, group_var) |> 
  mutate(id = 1:n(),
         word_id = as.factor(word) |> fct_inorder() |>  as.double(),
         max = cummax(word_id),
         coord_max = max(max)) |> 
  ungroup() |> 
  mutate(name = str_c(name, " (", age, ")")) |> 
  group_by(name, group_var, coord_max) |>
  summarise(id = max(id)) |> 
  ungroup() ->
  lexical_diversity

lexical_diversity |> 
  ggplot(aes(id, coord_max, group = name, label = name)) +
  geom_point(data = lexical_diversity |> select(-group_var), color = "grey80")+
  geom_point()+
  ggrepel::geom_label_repel()+
  facet_wrap(~group_var)+
  theme(legend.position = "bottom")+
  labs(x = "tokens",
       y = "types")
```

### Кластеризация людей

Я взял частотные 50 слов и кластеризовал людей на основе нормализованной частотности слов в текстах людей:

```{r}
mano_corpus |> 
  unnest_tokens(input = "text", output = "word", token = "words") |> 
  count(word, sort = TRUE) |>
  filter(!(word %in% c("kirikou", "karaba", "làà", "mɔ̀ɔ̀", "dàā", "yíí", "zíé", "wìì", "lòkóò"))) |> 
  slice_max(order_by = n, n = 50) |> 
  pull(word) ->
  freq_words

library(dendextend)

mano_corpus |> 
  mutate(name = str_c(name, " (", age, "):\t", group_var),
         color = scales::hue_pal()(5)[factor(group_var)]) |> 
  distinct(name, color) ->
  colors

mano_corpus |> 
  mutate(name = str_c(name, " (", age, "):\t", group_var)) |> 
  unnest_tokens(input = text, output = word, token = "words") |> 
  count(name, word)  |> 
  group_by(name) |> 
  mutate(total = sum(n),
            ratio = n/total,
            ratio_normalized = scale(ratio)[1]) |> 
  filter(word %in% freq_words) |> 
  select(name, word, ratio_normalized) |> 
  pivot_wider(names_from = word, values_from = ratio_normalized, values_fill = 0) |> 
  column_to_rownames("name") |>  
  dist(method = "manhattan") |> 
  hclust(method = "complete") |> 
  as.dendrogram() ->
  dend

par(mar=c(2,0,0,23))
dend |> 
  set("labels_col", colors$color[match(labels(dend), colors$name)]) |> 
  plot(horiz = TRUE)
```

### Векторизация

Я использую простенький word2vec и umap для уменьшения размерности:

```{r}
#| fig-height: 9
#| fig-width: 12

library(word2vec)

set.seed(42) 
model <- word2vec(x = mano_corpus$text, 
                  type = "skip-gram",
                  dim = 50,
                  window = 5,
                  iter = 20,
                  hs = TRUE,
                  min_count = 5,
                  threads = 6)
emb <- as.matrix(model)

library(uwot)
set.seed(42)
viz <- umap(emb,  n_neighbors = 15, n_threads = 2)

tibble(word = rownames(emb), 
       V1 = viz[, 1], 
       V2 = viz[, 2]) |> 
  ggplot(aes(x = V1, y = V2, label = word)) + 
  geom_text(size = 5, alpha = 0.4)
```

Слова находящиеся рядом должны иметь общую семантику. Эта картинка каждый раз перерисовывается с рандомизацией.

### Анализ коллокаций

Две меры коллокационности, посмотри верхушку списков:

```{r}
mano_corpus |> 
  unnest_tokens(input = "text", output = "ngram", token = "ngrams", n = 2) |> 
  separate(ngram, into = c("word1", "word2"), sep = " ") |>
  count(word1, word2) |> 
  mutate(N = sum(n)) |> 
  group_by(word1) |> 
  mutate(R1 = sum(n),
         R2 = N - R1) |> 
  group_by(word2) |> 
  mutate(C1 = sum(n),
         C2 = N - C1) |> 
  arrange(-R1, -C1) |> 
  ungroup() |> 
  rename(O11 = n) |> 
  mutate(O12 = R1-O11,
         O21 = C1-O11,
         O22 = C2-O12, # or R2-O21 
         E11 = R1 * C1 / N, 
         E12 = R1 * C2 / N,
         E21 = R2 * C1 / N, 
         E22 = R2 * C2 / N,
         MI = log2(O11 / E11),
         liddle = (O11*O22-O12*O21)/(C1*C2), # Liddell (1976)
         dice = 2*O11/(R1+C1), # Smadja et al. (1996)
         jaccard = O11/(O11+O12+O21),
         t.score = (O11 - E11) / sqrt(O11),
         X2 = (O11-E11)^2/E11 + (O12-E12)^2/E12 + (O21-E21)^2/E21 + (O22-E22)^2/E22,
         DP = O11 / R1 - O21 / R2) ->
  collacations

collacations |> 
  arrange(desc(t.score)) |> 
  select(word1, word2, O11, N, t.score) |> 
  rename(total = N,
         co_occurrence_frequency = O11)

collacations |> 
  arrange(desc(MI)) |> 
  select(word1, word2, O11, N, MI) |> 
  rename(total = N,
         co_occurrence_frequency = O11)
```

## Для составления списка стопслов

Можно идти по этому списку, листая страницы и выписывать стопслова. Пожалуйста, копирую отсюда написание --- я вносил правки в орфографию.

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = word) |> 
  count(word, sort = TRUE)
```

Я забыл задачу, для которой мы это делали, если мы хотим что-то узнать про тексты, то тогда нужно грамматические, а не лексические, а если мы хотим по ним кластеризовать людей, то тогда лексические.

## Количество фр. заимствований

Я буду считать, что ниже представлен список французского. Если я не прав, то скажи, я исключу что-то из списка.

```{r}
'á" "à" "ā" "a̰" "á̰" "à̰' |> 
  str_remove_all('["a ]') |> 
  str_c("ɓɛɲŋɔ]") ->
  non_french

non_french <- str_c("[", non_french)

mano_corpus |> 
  unnest_tokens(input = text, output = word) |> 
  count(word, sort = TRUE) |> 
  filter(str_detect(word, non_french, negate = TRUE))

mano_corpus |> 
  unnest_tokens(input = text, output = word) |> 
  count(word, sort = TRUE) |> 
  filter(str_detect(word, non_french, negate = TRUE)) |> 
  pull(word) ->
  french_words

french_words <- french_words[!(french_words %in% c("unp", "kirikou", "kiriki", "sociere", "sorc", "kiri", "kris", "sorciere", "singing", "onomat", "a", "eee", "__", "g", "hes", "kirikou", "karaba", "keelee", "mbe", "hesitation", "pascale", "s", "ts", "zi", "z", "e", "es", "we", "he̋"))] 

french_words
```

Значение по людям:

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = word) |> 
  mutate(french = if_else(word %in% french_words, "french", "non_french")) |> 
  count(name, age, group_var, french) |> 
  pivot_wider(names_from = french, values_from = n, values_fill = 0) ->
  french

french

french |> 
  mutate(name = str_c(name, " (", age, ")")) |> 
  ggplot(aes(non_french, french, color = group_var))+
  scale_x_log10()+
  scale_y_log10()+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  ggrepel::geom_text_repel(aes(label = name))+
  coord_fixed()+ 
  labs(x = "non french lexicon (log scaled)",
       y = "french lexicon (log scaled)")
```

## Количество ономатопей

```{r}
mano_corpus |> 
  mutate(onomatopoeia = str_extract_all(ft, "ONOMAT")) |>
  unnest_longer(onomatopoeia) |>
  select(name, age, group_var, onomatopoeia) |> 
  na.omit() |> 
  count(name, age, group_var)
```

Что-то они всего у семи людей...

## Diversity of tense marking

```{r}
mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(PST = str_count(chunk_structure, "PST"),
         JNT = str_count(chunk_structure, "JNT"),
         IPFV = str_count(chunk_structure, "IPFV"),
         PRED = str_count(chunk_structure, "PRED"),
         EXI = str_count(chunk_structure, "EXI"),
         CONJ = str_count(chunk_structure, "CONJ"),
         PRF = str_count(chunk_structure, "PRF"),
         FUT = str_count(chunk_structure, "FUT"),
         NEG.COND = str_count(chunk_structure, "NEG.COND"),
         NEG = str_count(chunk_structure, "NEG") - NEG.COND,
         COND = str_count(chunk_structure, "COND"),
         IMP = str_count(chunk_structure, "IMP"),
         PROSP = str_count(chunk_structure, "PROSP"),
         PROT.IRR = str_count(chunk_structure, "PROT.IRR"),
         APOD.IRR = str_count(chunk_structure, "APOD.IRR"),
         IRR = str_count(chunk_structure, "APOD.IRR"),
         PROH = str_count(chunk_structure, "PROH")) |> 
  select(-chunk_structure) ->
  tense

tense

tense |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(tense = case_when(tense %in% c("COND", "IRR", "PROT.IRR", "APOD.IRR", "NEG.COND") ~ "CONDs",
                           tense %in% c("PROH", "IMP") ~ "PROH or IMP",
                           tense %in% c("EXI", "PRED", "IPFV", "FUT", "PROSP") ~ "non-past",
                           TRUE ~ tense)) |> 
  group_by(name, age, group_var, tense) |>
  summarise(n = sum(n)) |> 
  group_by(name, age, group_var) |> 
  mutate(total = sum(n),
         ratio = n/total) |> 
  select(-n, -total) |> 
  ungroup() |> 
  mutate(name = str_c(name, " (", age, ")"),
         name = fct_reorder(name, age),
         tense = factor(tense, levels = c("CONDs", "PROH or IMP",
                                          "non-past","NEG", "CONJ",
                                          "PRF", "JNT", "PST")),
         label = str_c(round(ratio * 100), "%")) |>
  filter(ratio > 0) |>
  ggplot(aes(x = ratio, y = name, label = label, color = tense))+
  geom_col(aes(fill = tense))+
  geom_label(position = position_fill(vjust = 0.5), fill = "white")+
  scale_x_continuous(label = scales::percent)+
  labs(x = NULL, y = NULL)
```

Выкидываем JNT и PST

```{r}
tense |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(tense = case_when(tense %in% c("COND", "IRR", "PROT.IRR", "APOD.IRR", "NEG.COND") ~ "CONDs",
                           tense %in% c("PROH", "IMP") ~ "PROH or IMP",
                           tense %in% c("EXI", "PRED", "IPFV", "FUT", "PROSP") ~ "non-past",
                           TRUE ~ tense)) |> 
  filter(!(tense %in% c("JNT", "PST"))) |> 
  group_by(name, age, group_var, tense) |>
  summarise(n = sum(n)) |> 
  group_by(name, age, group_var) |> 
  mutate(total = sum(n),
         ratio = n/total) |> 
  select(-n, -total) |> 
  ungroup() |> 
  mutate(name = str_c(name, " (", age, ")"),
         name = fct_reorder(name, age),
         tense = factor(tense, levels = c("CONDs", "PROH or IMP",
                                          "non-past","NEG", "CONJ",
                                          "PRF", "JNT", "PST")),
         label = str_c(round(ratio * 100), "%")) |>
  filter(ratio > 0) |>
  ggplot(aes(x = ratio, y = name, label = label, color = tense))+
  geom_col(aes(fill = tense))+
  geom_label(position = position_fill(vjust = 0.5), fill = "white")+
  scale_x_continuous(label = scales::percent)+
  labs(x = NULL, y = NULL)
```


График соотношения количества JNT и PST

```{r}
tense |> 
  mutate(PST = if_else(PST == 0, 0.9, PST),
         JNT = if_else(JNT == 0, 0.9, JNT)) |> 
  select(name, age, group_var, PST, JNT) |> 
  mutate(ratio = PST/(PST+JNT)) |> 
  arrange(-ratio)

tense |> 
  mutate(PST = if_else(PST == 0, 0.9, PST),
         JNT = if_else(JNT == 0, 0.9, JNT)) |> 
  select(name, age, group_var, PST, JNT) |> 
  mutate(ratio = PST/(PST+JNT),
         name = str_c(name, " (", age, ")")) |> 
  ggplot(aes(PST, JNT, color = group_var))+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  ggrepel::geom_text_repel(aes(label = name))+
  coord_fixed()
```

JNT.SAY vs JNT без SAY

```{r}
mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(JNT.SAY = str_count(chunk_structure, "JNT.SAY"),
         JNT = str_count(chunk_structure, "JNT") - JNT.SAY,
         ratio = JNT/(JNT+JNT.SAY)) |> 
  select(-chunk_structure) |>
  arrange(-ratio)

mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(JNT.SAY = str_count(chunk_structure, "JNT.SAY"),
         JNT = str_count(chunk_structure, "JNT") - JNT.SAY,
         JNT.SAY = if_else(JNT.SAY == 0, 0.9, JNT.SAY),
         JNT = if_else(JNT == 0, 0.9, JNT),
         name = str_c(name, " (", age, ")")) |> 
  select(-chunk_structure) |>
  ggplot(aes(JNT, JNT.SAY, color = group_var))+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  coord_fixed()+
  ggrepel::geom_text_repel(aes(label = name))
```

PST + JNT vs other

```{r}
tense |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(pst_jnt_other = if_else(str_detect(tense, "(PST)|(JNT)"), 
                                 "PST_or_JNT",
                                 "other")) |> 
  group_by(name, age, group_var, pst_jnt_other) |> 
  summarise(n = sum(n)) |> 
  pivot_wider(names_from = pst_jnt_other, values_from = n, values_fill = 0) |> 
  mutate(ratio = PST_or_JNT/(PST_or_JNT+other)) |> 
  arrange(-ratio)

tense |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(pst_jnt_other = if_else(str_detect(tense, "(PST)|(JNT)"), 
                                 "PST_or_JNT",
                                 "other")) |> 
  group_by(name, age, group_var, pst_jnt_other) |> 
  summarise(n = sum(n)) |> 
  pivot_wider(names_from = pst_jnt_other, values_from = n, values_fill = 0) |> 
  mutate(PST_or_JNT = if_else(PST_or_JNT == 0, 0.9, PST_or_JNT),
         other = if_else(other == 0, 0.9, other),
         name = str_c(name, " (", age, ")")) |> 
  ggplot(aes(PST_or_JNT, other, color = group_var))+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  coord_fixed()+
  ggrepel::geom_text_repel(aes(label = name))
```


```{r}
#| include: false

library(tidyverse)
library(ggrepel)

tense |> 
  mutate(name = str_c(name, " (", age, ")")) |> 
  pivot_longer(names_to = "tense", values_to = "value", -c(name, age, group_var)) |>  
  mutate(tense = case_when(tense %in% c("COND", "IRR", "PROT.IRR", "APOD.IRR", "NEG.COND") ~ "CONDs",
                           tense %in% c("PROH", "IMP") ~ "PROH or IMP",
                           tense %in% c("EXI", "PRED", "IPFV", "FUT", "PROSP") ~ "non-past",
                           TRUE ~ tense)) |> 
  group_by(name, age, group_var, tense) |>
  summarise(value = sum(value)) |> 
  #  select(name, PST, JNT, IPFV, PRED) |> 
  #  mutate(across(where(is.integer), scales::rescale)) |> 
  group_by(name) |>  
  mutate(label = if_else(tense == "PST", name, NA),
         value = if_else(value == 0, 0.9, value)) |> 
  ungroup() |> 
  mutate(tense = fct_reorder(tense, value)) |> 
  ggplot(aes(tense, value, group = name, label = label, color = group_var))+
  geom_point()+
  geom_line(alpha = 0.5)+
  geom_text_repel(nudge_x = 2,
                  segment.color = "gray80",
                  force = 5,
                  max.overlaps = 40,
                  point.padding = 0.2,
                  na.rm = TRUE)+
  theme(legend.position = "bottom")+
  labs(x = NULL, y = "ratio")

tense |> 
  mutate(name = str_c(name, " (", age, ")")) |> 
  pivot_longer(names_to = "tense", values_to = "value", -c(name, age, group_var)) |>  
  mutate(tense = case_when(tense %in% c("COND", "IRR", "PROT.IRR", "APOD.IRR", "NEG.COND") ~ "CONDs",
                           tense %in% c("PROH", "IMP") ~ "PROH or IMP",
                           tense %in% c("EXI", "PRED", "IPFV", "FUT", "PROSP") ~ "non-past",
                           TRUE ~ tense)) |> 
  group_by(name, age, group_var, tense) |>
  summarise(value = sum(value)) |> 
  group_by(name, age, group_var) |> 
  mutate(total = sum(value),
         ratio = value/total) |> 
  select(-value, -total) |> 
  rename(value = ratio) |> 
#  select(name, PST, JNT, IPFV, PRED) |> 
#  mutate(across(where(is.integer), scales::rescale)) |> 
  group_by(name) |>  
  mutate(label = if_else(tense == "PST", name, NA),
         value = if_else(value == 0, 0.9, value)) |> 
  ungroup() |> 
  mutate(tense = fct_reorder(tense, value)) |> 
  ggplot(aes(tense, value, group = name, label = label, color = group_var))+
  geom_point()+
  geom_line(alpha = 0.5)+
  geom_text_repel(nudge_x = 2,
                  segment.color = "gray80",
                  force = 5,
                  max.overlaps = 40,
                  point.padding = 0.2,
                  na.rm = TRUE)+
  theme(legend.position = "bottom")+
  labs(x = NULL, y = "ratio") # + 
  # coord_polar()
```


## Diversity of tense marking in rs

```{r}
extract_and_concatenate_rs <- function(string){
  string |> 
    str_extract_all("rs%.*?%") |> 
    unlist() |> 
    str_remove_all("rs%") |> 
    str_remove_all("%") |> 
    str_c(collapse = " ")
}

mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(rs = map_chr(mano_corpus$chunk_structure, extract_and_concatenate_rs),
         PST = str_count(rs, "PST"),
         JNT = str_count(rs, "JNT"),
         IPFV = str_count(rs, "IPFV"),
         PRED = str_count(rs, "PRED"),
         EXI = str_count(rs, "EXI"),
         CONJ = str_count(rs, "CONJ"),
         PRF = str_count(rs, "PRF"),
         FUT = str_count(rs, "FUT"),
         NEG.COND = str_count(rs, "NEG.COND"),
         NEG = str_count(rs, "NEG") - NEG.COND,
         COND = str_count(rs, "COND"),
         IMP = str_count(rs, "IMP"),
         PROSP = str_count(rs, "PROSP"),
         PROT.IRR = str_count(rs, "PROT.IRR"),
         APOD.IRR = str_count(rs, "APOD.IRR"),
         IRR = str_count(rs, "APOD.IRR"),
         PROH = str_count(rs, "PROH")) |> 
  select(-chunk_structure, -rs) ->
  tense_rs

tense_rs

tense_rs |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(tense = case_when(tense %in% c("COND", "IRR", "PROT.IRR", "APOD.IRR", "NEG.COND") ~ "CONDs",
                           tense %in% c("PROH", "IMP") ~ "PROH or IMP",
                           tense %in% c("EXI", "PRED", "IPFV", "FUT", "PROSP") ~ "non-past",
                           TRUE ~ tense)) |> 
  group_by(name, age, group_var, tense) |>
  summarise(n = sum(n)) |> 
  group_by(name, age, group_var) |> 
  mutate(total = sum(n),
         ratio = n/total) |> 
  select(-n, -total) |> 
  ungroup() |> 
  mutate(name = str_c(name, " (", age, ")"),
         name = fct_reorder(name, age),
         tense = factor(tense, levels = c("CONDs", "PROH or IMP",
                                          "non-past","NEG", "CONJ",
                                          "PRF", "JNT", "PST")),
         label = str_c(round(ratio * 100), "%")) |>
  filter(ratio > 0) |>
  ggplot(aes(x = ratio, y = name, label = label, color = tense))+
  geom_col(aes(fill = tense))+
  geom_label(position = position_fill(vjust = 0.5), fill = "white")+
  scale_x_continuous(label = scales::percent)+
  labs(x = NULL, y = NULL,
       caption = "within the reported speech")
```

Выкидываем JNT и PST

```{r}
tense_rs |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(tense = case_when(tense %in% c("COND", "IRR", "PROT.IRR", "APOD.IRR", "NEG.COND") ~ "CONDs",
                           tense %in% c("PROH", "IMP") ~ "PROH or IMP",
                           tense %in% c("EXI", "PRED", "IPFV", "FUT", "PROSP") ~ "non-past",
                           TRUE ~ tense)) |> 
  filter(!(tense %in% c("JNT", "PST"))) |> 
  group_by(name, age, group_var, tense) |>
  summarise(n = sum(n)) |> 
  group_by(name, age, group_var) |> 
  mutate(total = sum(n),
         ratio = n/total) |> 
  select(-n, -total) |> 
  ungroup() |> 
  mutate(name = str_c(name, " (", age, ")"),
         name = fct_reorder(name, age),
         tense = factor(tense, levels = c("CONDs", "PROH or IMP",
                                          "non-past","NEG", "CONJ",
                                          "PRF", "JNT", "PST")),
         label = str_c(round(ratio * 100), "%")) |>
  filter(ratio > 0) |>
  ggplot(aes(x = ratio, y = name, label = label, color = tense))+
  geom_col(aes(fill = tense))+
  geom_label(position = position_fill(vjust = 0.5), fill = "white")+
  scale_x_continuous(label = scales::percent)+
  labs(x = NULL, y = NULL,
       caption = "within the reported speech")
```

График соотношения количества JNT и PST

```{r}
tense_rs |> 
  mutate(PST = if_else(PST == 0, 0.9, PST),
         JNT = if_else(JNT == 0, 0.9, JNT)) |> 
  select(name, age, group_var, PST, JNT) |> 
  mutate(ratio = PST/(PST+JNT)) |> 
  arrange(-ratio)

tense_rs |> 
  mutate(PST = if_else(PST == 0, 0.9, PST),
         JNT = if_else(JNT == 0, 0.9, JNT)) |> 
  select(name, age, group_var, PST, JNT) |> 
  mutate(ratio = PST/(PST+JNT),
         name = str_c(name, " (", age, ")")) |> 
  ggplot(aes(PST, JNT, color = group_var))+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  coord_fixed()+
  ggrepel::geom_text_repel(aes(label = name))+
  labs(caption = "within the reported speech")
```

JNT.SAY vs JNT без SAY

```{r}
mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(chunk_structure = map_chr(mano_corpus$chunk_structure, extract_and_concatenate_rs),
         JNT.SAY = str_count(chunk_structure, "JNT.SAY"),
         JNT = str_count(chunk_structure, "JNT") - JNT.SAY,
         ratio = JNT/(JNT+JNT.SAY)) |> 
  select(-chunk_structure) |>
  arrange(-ratio)

mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(chunk_structure = map_chr(mano_corpus$chunk_structure, extract_and_concatenate_rs),
         JNT.SAY = str_count(chunk_structure, "JNT.SAY"),
         JNT = str_count(chunk_structure, "JNT") - JNT.SAY,
         JNT.SAY = if_else(JNT.SAY == 0, 0.9, JNT.SAY),
         JNT = if_else(JNT == 0, 0.9, JNT),
         name = str_c(name, " (", age, ")")) |> 
  select(-chunk_structure) |>
  ggplot(aes(JNT, JNT.SAY, color = group_var))+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  coord_fixed()+
  ggrepel::geom_text_repel(aes(label = name))+
  labs(caption = "within the reported speech")
```

PST + JNT vs other

```{r}
tense_rs |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(pst_jnt_other = if_else(str_detect(tense, "(PST)|(JNT)"), 
                                 "PST_or_JNT",
                                 "other")) |> 
  group_by(name, age, group_var, pst_jnt_other) |> 
  summarise(n = sum(n)) |> 
  pivot_wider(names_from = pst_jnt_other, values_from = n, values_fill = 0) |> 
  mutate(ratio = PST_or_JNT/(PST_or_JNT+other)) |> 
  arrange(-ratio)

tense_rs |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(pst_jnt_other = if_else(str_detect(tense, "(PST)|(JNT)"), 
                                 "PST_or_JNT",
                                 "other")) |> 
  group_by(name, age, group_var, pst_jnt_other) |> 
  summarise(n = sum(n)) |> 
  pivot_wider(names_from = pst_jnt_other, values_from = n, values_fill = 0) |> 
  mutate(PST_or_JNT = if_else(PST_or_JNT == 0, 0.9, PST_or_JNT),
         other = if_else(other == 0, 0.9, other),
         name = str_c(name, " (", age, ")")) |> 
  ggplot(aes(PST_or_JNT, other, color = group_var))+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  coord_fixed()+
  coord_fixed() +
  ggrepel::geom_text_repel(aes(label = name))+
  labs(caption = "within the reported speech")
```

```{r}
mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(ors = str_remove_all(chunk_structure, "rs%.*?%"),
         PST = str_count(ors, "PST"),
         JNT = str_count(ors, "JNT"),
         IPFV = str_count(ors, "IPFV"),
         PRED = str_count(ors, "PRED"),
         EXI = str_count(ors, "EXI"),
         CONJ = str_count(ors, "CONJ"),
         PRF = str_count(ors, "PRF"),
         FUT = str_count(ors, "FUT"),
         NEG.COND = str_count(ors, "NEG.COND"),
         NEG = str_count(ors, "NEG") - NEG.COND,
         COND = str_count(ors, "COND"),
         IMP = str_count(ors, "IMP"),
         PROSP = str_count(ors, "PROSP"),
         PROT.IRR = str_count(ors, "PROT.IRR"),
         APOD.IRR = str_count(ors, "APOD.IRR"),
         IRR = str_count(ors, "APOD.IRR"),
         PROH = str_count(ors, "PROH")) |> 
  select(-chunk_structure, -ors) ->
  tense_ors

tense_ors |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(tense = case_when(tense %in% c("COND", "IRR", "PROT.IRR", "APOD.IRR", "NEG.COND") ~ "CONDs",
                           tense %in% c("PROH", "IMP") ~ "PROH or IMP",
                           tense %in% c("EXI", "PRED", "IPFV", "FUT", "PROSP") ~ "non-past",
                           TRUE ~ tense)) |> 
  group_by(name, age, group_var, tense) |>
  summarise(n = sum(n)) |> 
  group_by(name, age, group_var) |> 
  mutate(total = sum(n),
         ratio = n/total) |> 
  select(-n, -total) |> 
  ungroup() |> 
  mutate(name = str_c(name, " (", age, ")"),
         name = fct_reorder(name, age),
         tense = factor(tense, levels = c("CONDs", "PROH or IMP",
                                          "non-past","NEG", "CONJ",
                                          "PRF", "JNT", "PST")),
         label = str_c(round(ratio * 100), "%")) |>
  filter(ratio > 0) |>
  ggplot(aes(x = ratio, y = name, label = label, color = tense))+
  geom_col(aes(fill = tense))+
  geom_label(position = position_fill(vjust = 0.5), fill = "white")+
  scale_x_continuous(label = scales::percent)+
  labs(x = NULL, y = NULL,
       caption = "without chunks of the reported speech")
```

Выкидываем JNT и PST

```{r}
tense_ors |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(tense = case_when(tense %in% c("COND", "IRR", "PROT.IRR", "APOD.IRR", "NEG.COND") ~ "CONDs",
                           tense %in% c("PROH", "IMP") ~ "PROH or IMP",
                           tense %in% c("EXI", "PRED", "IPFV", "FUT", "PROSP") ~ "non-past",
                           TRUE ~ tense)) |> 
  filter(!(tense %in% c("JNT", "PST"))) |> 
  group_by(name, age, group_var, tense) |>
  summarise(n = sum(n)) |> 
  group_by(name, age, group_var) |> 
  mutate(total = sum(n),
         ratio = n/total) |> 
  select(-n, -total) |> 
  ungroup() |> 
  mutate(name = str_c(name, " (", age, ")"),
         name = fct_reorder(name, age),
         tense = factor(tense, levels = c("CONDs", "PROH or IMP",
                                          "non-past","NEG", "CONJ",
                                          "PRF", "JNT", "PST")),
         label = str_c(round(ratio * 100), "%")) |>
  filter(ratio > 0) |>
  ggplot(aes(x = ratio, y = name, label = label, color = tense))+
  geom_col(aes(fill = tense))+
  geom_label(position = position_fill(vjust = 0.5), fill = "white")+
  scale_x_continuous(label = scales::percent)+
  labs(x = NULL, y = NULL,
       caption = "without chunks of the reported speech")
```

График соотношения количества JNT и PST

```{r}
tense_ors |> 
  mutate(PST = if_else(PST == 0, 0.9, PST),
         JNT = if_else(JNT == 0, 0.9, JNT)) |> 
  select(name, age, group_var, PST, JNT) |> 
  mutate(ratio = PST/(PST+JNT)) |> 
  arrange(-ratio)

tense_ors |> 
  mutate(PST = if_else(PST == 0, 0.9, PST),
         JNT = if_else(JNT == 0, 0.9, JNT)) |> 
  select(name, age, group_var, PST, JNT) |> 
  mutate(ratio = PST/(PST+JNT),
         name = str_c(name, " (", age, ")")) |> 
  ggplot(aes(PST, JNT, color = group_var))+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  coord_fixed()+
  ggrepel::geom_text_repel(aes(label = name))+
  labs(caption = "without chunks of the reported speech")
```

JNT.SAY vs JNT без SAY

```{r}
mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(chunk_structure = str_remove_all(chunk_structure, "rs%.*?%"),
         JNT.SAY = str_count(chunk_structure, "JNT.SAY"),
         JNT = str_count(chunk_structure, "JNT") - JNT.SAY,
         ratio = JNT/(JNT+JNT.SAY)) |> 
  select(-chunk_structure) |>
  arrange(-ratio)

mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(chunk_structure = str_remove_all(chunk_structure, "rs%.*?%"),
         JNT.SAY = str_count(chunk_structure, "JNT.SAY"),
         JNT = str_count(chunk_structure, "JNT") - JNT.SAY,
         JNT.SAY = if_else(JNT.SAY == 0, 0.9, JNT.SAY),
         JNT = if_else(JNT == 0, 0.9, JNT),
         name = str_c(name, " (", age, ")")) |> 
  select(-chunk_structure) |>
  ggplot(aes(JNT, JNT.SAY, color = group_var))+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  coord_fixed()+
  ggrepel::geom_text_repel(aes(label = name))+
  labs(caption = "without chunks of the reported speech")
```

PST + JNT vs other

```{r}
tense_ors |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(pst_jnt_other = if_else(str_detect(tense, "(PST)|(JNT)"), 
                                 "PST_or_JNT",
                                 "other")) |> 
  group_by(name, age, group_var, pst_jnt_other) |> 
  summarise(n = sum(n)) |> 
  pivot_wider(names_from = pst_jnt_other, values_from = n, values_fill = 0) |> 
  mutate(ratio = PST_or_JNT/(PST_or_JNT+other)) |> 
  arrange(-ratio)

tense_ors |> 
  pivot_longer(names_to = "tense", values_to = "n", -c(name, age, group_var)) |> 
  mutate(pst_jnt_other = if_else(str_detect(tense, "(PST)|(JNT)"), 
                                 "PST_or_JNT",
                                 "other")) |> 
  group_by(name, age, group_var, pst_jnt_other) |> 
  summarise(n = sum(n)) |> 
  pivot_wider(names_from = pst_jnt_other, values_from = n, values_fill = 0) |> 
  mutate(PST_or_JNT = if_else(PST_or_JNT == 0, 0.9, PST_or_JNT),
         other = if_else(other == 0, 0.9, other),
         name = str_c(name, " (", age, ")")) |> 
  ggplot(aes(PST_or_JNT, other, color = group_var))+
  geom_smooth(method = "lm", se = FALSE, color = "grey60", linetype = 2)+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  coord_fixed()+
  ggrepel::geom_text_repel(aes(label = name))+
  labs(caption = "without chunks of the reported speech")
```

## сложный синтаксис

обсчитать префиксы маленькими перед квадратными, треугольными и фигурными скобками

```{r}
mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(foc = str_count(chunk_structure, "foc"),
         rel = str_count(chunk_structure, "rel"),
         temp = str_count(chunk_structure, "temp"),
         cond = str_count(chunk_structure, "cond"),
          purp = str_count(chunk_structure, "purp"),
         prec = str_count(chunk_structure, "prec"),
         compar = str_count(chunk_structure, "compar"),
         mod = str_count(chunk_structure, "mod"),
         sa = str_count(chunk_structure, "sa"),
         le = str_count(chunk_structure, "le"),
         ht = str_count(chunk_structure, "ht"),
         at = str_count(chunk_structure, "at"),
         top = str_count(chunk_structure, "top"),
         voc = str_count(chunk_structure, "voc")) |> 
  select(-chunk_structure) ->
  syntax

syntax
```

## reference tracking 

обсчитать, сколько CR vs SR в NP и в pro

```{r}
mano_corpus |> 
  select(name, age, group_var, chunk_structure) |> 
  mutate(pro_CR = str_count(chunk_structure, "pro\\(CR\\)"),
         NP_CR = str_count(chunk_structure, "NP\\(CR\\)"),
         pro_SR = str_count(chunk_structure, "pro\\(SR\\)"),
         NP_SR = str_count(chunk_structure, "NP\\(SR\\)")) |> 
  select(-chunk_structure) ->
  reference_tracking

reference_tracking
```

## Сколько всего?

```{r}
mano_corpus |> 
  mutate(n_predecations = str_count(chunk_structure, "\\[")) |> 
  select(name, age, group_var, n_chunks, n_predecations) |> 
  arrange(-n_predecations)
```

## Уменьшение размерности

Я сделал мега-таблицу, с 

- 50 самых частотных слов
- количество французских заимствований
- время (таблица выше)
- синтаксис
- reference_tracking

Итого 95 переменных.

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = word, token = "words") |> 
  count(name, age, group_var, word)  |> 
  filter(word %in% freq_words) |> 
  pivot_wider(names_from = word, values_from = n, values_fill = 0)  ->
  lexicon

syntax |> 
  full_join(tense) |> 
  full_join(lexicon) |> 
  full_join(reference_tracking) |>  
  full_join(french) |> 
  mutate(french = if_else(is.na(french), 0, french)) |> 
  mutate(across(-c(name, age, group_var), function(x) scale(x))) |> 
  select(-c(name, age, group_var)) |> 
  prcomp() ->
  pca

syntax |> 
  select(name, age, group_var) |> 
  bind_cols(pca$x) |> 
  ggplot(aes(PC1, PC2, color = group_var))+
  geom_point()+
  ggrepel::geom_text_repel(aes(label = str_c(name, " (", age, ")")), max.overlaps = 100)
```

Вроде CS, Cecile_Mamy 12, и Michel_Sonomy -- авторы текстов, где больше всего предикаций...


Всякие вопросы:

Что будет если не нормализовывать?

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = word, token = "words") |> 
  count(name, age, group_var, word)  |> 
  filter(word %in% freq_words) |> 
  pivot_wider(names_from = word, values_from = n, values_fill = 0)  ->
  lexicon

syntax |> 
  full_join(tense) |> 
  full_join(lexicon) |> 
  full_join(reference_tracking) |>  
  full_join(french) |> 
  mutate(french = if_else(is.na(french), 0, french)) |> 
  select(-c(name, age, group_var)) |> 
  prcomp() ->
  pca

syntax |> 
  select(name, age, group_var) |> 
  bind_cols(pca$x) |> 
  ggplot(aes(PC1, PC2, color = group_var))+
  geom_point()+
  ggrepel::geom_text_repel(aes(label = str_c(name, " (", age, ")")), max.overlaps = 100)
```

Что будет если выкинуть авторов длинных текстов?

```{r}
mano_corpus |> 
  unnest_tokens(input = text, output = word, token = "words") |> 
  count(name, age, group_var, word)  |> 
  filter(word %in% freq_words) |> 
  pivot_wider(names_from = word, values_from = n, values_fill = 0)  ->
  lexicon

syntax |> 
  full_join(tense) |> 
  full_join(lexicon) |> 
  full_join(reference_tracking) |>  
  full_join(french) |> 
  mutate(french = if_else(is.na(french), 0, french)) |> 
  mutate(name2 = str_c(name, " (", age, ")")) |> 
  filter(!(name2 %in% c("CS (100)", "Michel_Sonomy (15)", "Cecile_Mamy (12)"))) |> 
  select(-c(name, name2, age, group_var)) |> 
  prcomp() ->
  pca

syntax |> 
  mutate(name2 = str_c(name, " (", age, ")")) |> 
  filter(!(name2 %in% c("CS (100)", "Michel_Sonomy (15)", "Cecile_Mamy (12)"))) |> 
  select(name, age, group_var) |> 
  bind_cols(pca$x) |> 
  ggplot(aes(PC1, PC2, color = group_var))+
  geom_point()+
  ggrepel::geom_text_repel(aes(label = str_c(name, " (", age, ")")), max.overlaps = 100)
```

## Для статьи

Я получил вот такие вот длительности 

```{r}
library(lubridate)

ma_ch_ki <- readxl::read_xlsx("kirikou_annotations.xlsx", sheet = "kirikou Mano") |>
  select(name, source, `temps de fin - hh:mm:ss.ms`, `Temps de départ - hh:mm:ss.ms`)
ma_ch_fo <- readxl::read_xlsx("kirikou_annotations.xlsx", sheet = "folktales Mano children") |>
  select(name, source, `temps de fin - hh:mm:ss.ms`, `Temps de départ - hh:mm:ss.ms`)
ma_ad_fo <- readxl::read_xlsx("kirikou_annotations.xlsx", sheet = "folktales Mano adults") |>
  select(name, source, `temps de fin - hh:mm:ss.ms`, `Temps de départ - hh:mm:ss.ms`)
kp_ad_fo <- readxl::read_xlsx("kirikou_annotations.xlsx", sheet = "folktales Kpelle adults") |>
  select(name, source, `temps de fin - hh:mm:ss.ms`, `Temps de départ - hh:mm:ss.ms`)
kp_ch_fo <- readxl::read_xlsx("kirikou_annotations.xlsx", sheet = "folktales Kpelle children") |>
  select(name, source, `temps de fin - hh:mm:ss.ms`, `Temps de départ - hh:mm:ss.ms`)

ma_ch_ki |>
  bind_rows(ma_ch_fo, ma_ad_fo, kp_ad_fo, kp_ch_fo) |> 
  rename(time_start = `Temps de départ - hh:mm:ss.ms`,
         time_end = `temps de fin - hh:mm:ss.ms`) |> 
  group_by(name, source) |> 
  summarise(time_start = min(time_start),
            time_end = max(time_end),
            duration = time_end-time_start) |> 
  select(-time_start, -time_end) ->
  corpus_duration

corpus_duration

corpus_duration |> 
  ungroup() |> 
  summarise(duration = sum(duration)) |> 
  pull(duration) |> 
  as.duration() ->
  total_duration

total_duration
```

Общая длительность корпуса 2 часа 50 минут.


Overall, in our corpus they were used X and Y times respectively, or ??? and ???%, out of ??? finite predications total.

```{r}
mano_corpus |> 
  mutate(pst = str_count(chunk_structure, "PST"),
         jnt = str_count(chunk_structure, "JNT")) |> 
  summarise(pst = sum(pst),
            jnt = sum(jnt)) ->
  pst_jnt

mano_corpus |> 
  mutate(n_predecations = str_count(chunk_structure, "\\[")) |> 
  select(name, age, group_var, n_chunks, n_predecations) |> 
  arrange(-n_predecations) |> 
  summarise(n_predecations = sum(n_predecations)) ->
  n_predecations

percantage <- round((pst_jnt$pst + pst_jnt$jnt)/n_predecations*100)
```

Overall, in our corpus they were used `r pst_jnt$pst` and `r pst_jnt$jnt` times respectively, or  and `r percantage`%, out of `r n_predecations` finite predications total.